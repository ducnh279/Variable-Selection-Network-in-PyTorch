{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34b377e",
   "metadata": {
    "papermill": {
     "duration": 0.007664,
     "end_time": "2024-01-01T19:29:31.284892",
     "exception": false,
     "start_time": "2024-01-01T19:29:31.277228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e552fd1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:31.301300Z",
     "iopub.status.busy": "2024-01-01T19:29:31.300886Z",
     "iopub.status.idle": "2024-01-01T19:29:44.882010Z",
     "shell.execute_reply": "2024-01-01T19:29:44.880775Z"
    },
    "papermill": {
     "duration": 13.592588,
     "end_time": "2024-01-01T19:29:44.884824",
     "exception": false,
     "start_time": "2024-01-01T19:29:31.292236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "import lightgbm as lgb\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9f5527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:44.901672Z",
     "iopub.status.busy": "2024-01-01T19:29:44.900768Z",
     "iopub.status.idle": "2024-01-01T19:29:44.910838Z",
     "shell.execute_reply": "2024-01-01T19:29:44.909891Z"
    },
    "papermill": {
     "duration": 0.020838,
     "end_time": "2024-01-01T19:29:44.913085",
     "exception": false,
     "start_time": "2024-01-01T19:29:44.892247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = Path('/kaggle/input/icr-identify-age-related-conditions')\n",
    "OUTPUT_PATH = Path('/kaggle/working')\n",
    "ORIGINAL_FEATURES = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n",
    "       'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n",
    "       'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n",
    "       'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n",
    "       'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\n",
    "\n",
    "TARGET = 'Class'\n",
    "\n",
    "N_CORES = mp.cpu_count()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_FEATURES = len(ORIGINAL_FEATURES)\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 20\n",
    "N_WARMUPS = 0\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.005\n",
    "SEED = 252"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beced216",
   "metadata": {
    "papermill": {
     "duration": 0.006972,
     "end_time": "2024-01-01T19:29:44.927325",
     "exception": false,
     "start_time": "2024-01-01T19:29:44.920353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54fe002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:44.943105Z",
     "iopub.status.busy": "2024-01-01T19:29:44.942730Z",
     "iopub.status.idle": "2024-01-01T19:29:45.005138Z",
     "shell.execute_reply": "2024-01-01T19:29:45.003966Z"
    },
    "papermill": {
     "duration": 0.073392,
     "end_time": "2024-01-01T19:29:45.007812",
     "exception": false,
     "start_time": "2024-01-01T19:29:44.934420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv').drop(['Id'], axis=1)\n",
    "test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "greeks = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc5577",
   "metadata": {
    "papermill": {
     "duration": 0.007123,
     "end_time": "2024-01-01T19:29:45.022621",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.015498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66de6b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:45.039742Z",
     "iopub.status.busy": "2024-01-01T19:29:45.038897Z",
     "iopub.status.idle": "2024-01-01T19:29:45.046448Z",
     "shell.execute_reply": "2024-01-01T19:29:45.045586Z"
    },
    "papermill": {
     "duration": 0.018844,
     "end_time": "2024-01-01T19:29:45.048815",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.029971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "\n",
    "    # Calculate the number of observations for each class\n",
    "    N_0 = torch.sum(1 - y_true)\n",
    "    N_1 = torch.sum(y_true)\n",
    "    \n",
    "    # Calculate the predicted probabilities for each class\n",
    "    p_1 = torch.clamp(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    \n",
    "    # Calculate the average log loss for each class\n",
    "    log_loss_0 = -torch.sum((1 - y_true) * torch.log(p_0)) / N_0\n",
    "    log_loss_1 = -torch.sum(y_true * torch.log(p_1)) / N_1\n",
    "    \n",
    "    # Return the (not further weighted) average of the averages\n",
    "    a = (log_loss_0 + log_loss_1) / 2\n",
    "    \n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d76aa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:45.065932Z",
     "iopub.status.busy": "2024-01-01T19:29:45.065218Z",
     "iopub.status.idle": "2024-01-01T19:29:45.072757Z",
     "shell.execute_reply": "2024-01-01T19:29:45.071985Z"
    },
    "papermill": {
     "duration": 0.018734,
     "end_time": "2024-01-01T19:29:45.075039",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.056305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    # y_true: correct labels 0, 1\n",
    "    # y_pred: predicted probabilities of class=1\n",
    "    # Implements the Evaluation equation with w_0 = w_1 = 1.\n",
    "    # Calculate the number of observations for each class\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    # Calculate the average log loss for each class\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    # return the (not further weighted) average of the averages\n",
    "    a = (log_loss_0 + log_loss_1)/2\n",
    "    return 'Loss', a, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e361bb",
   "metadata": {
    "papermill": {
     "duration": 0.007147,
     "end_time": "2024-01-01T19:29:45.089796",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.082649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5-seed ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95ac841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:45.106903Z",
     "iopub.status.busy": "2024-01-01T19:29:45.106118Z",
     "iopub.status.idle": "2024-01-01T19:29:45.120541Z",
     "shell.execute_reply": "2024-01-01T19:29:45.119708Z"
    },
    "papermill": {
     "duration": 0.025846,
     "end_time": "2024-01-01T19:29:45.123013",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.097167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n",
    "       'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n",
    "       'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n",
    "       'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n",
    "       'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\n",
    "\n",
    "train['EJ'] = train['EJ'].str.strip()\n",
    "test['EJ'] = test['EJ'].str.strip()\n",
    "\n",
    "train['EJ'] = train['EJ'].map({'A': 1, 'B': 0})\n",
    "test['EJ'] = test['EJ'].map({'A': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f2d921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:45.140285Z",
     "iopub.status.busy": "2024-01-01T19:29:45.139534Z",
     "iopub.status.idle": "2024-01-01T19:29:45.156933Z",
     "shell.execute_reply": "2024-01-01T19:29:45.156113Z"
    },
    "papermill": {
     "duration": 0.028755,
     "end_time": "2024-01-01T19:29:45.159384",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.130629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "X = train[features]\n",
    "y = train['Class']\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(skf.split(X, y)):\n",
    "    train.loc[train.index.isin(val_idx), 'fold'] = fold + 1\n",
    "train['fold'] = train['fold'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfeee14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:45.176830Z",
     "iopub.status.busy": "2024-01-01T19:29:45.176092Z",
     "iopub.status.idle": "2024-01-01T19:29:45.184622Z",
     "shell.execute_reply": "2024-01-01T19:29:45.183872Z"
    },
    "papermill": {
     "duration": 0.019749,
     "end_time": "2024-01-01T19:29:45.186918",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.167169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_folds(train, features, target):\n",
    "    X = train[features]\n",
    "    y = train[target]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    fold = 0\n",
    "    for train_indices, val_indices in skf.split(X, y):\n",
    "        fold += 1\n",
    "        print(f'Preparing fold {fold} ...')\n",
    "        df_train = train.loc[train.index.isin(train_indices)].reset_index(drop=True)\n",
    "        df_val = train.loc[train.index.isin(val_indices)].reset_index(drop=True)\n",
    "        \n",
    "        df_train[features] = scaler.fit_transform(df_train[features])\n",
    "        df_val[features] = scaler.transform(df_val[features])\n",
    "        \n",
    "        df_train.to_csv(f'df_train_fold_{fold}.csv', index=False)\n",
    "        df_val.to_csv(f'df_val_fold_{fold}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d4d2037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:45.204241Z",
     "iopub.status.busy": "2024-01-01T19:29:45.203491Z",
     "iopub.status.idle": "2024-01-01T19:29:45.755298Z",
     "shell.execute_reply": "2024-01-01T19:29:45.753919Z"
    },
    "papermill": {
     "duration": 0.563143,
     "end_time": "2024-01-01T19:29:45.757695",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.194552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing fold 1 ...\n",
      "Preparing fold 2 ...\n",
      "Preparing fold 3 ...\n",
      "Preparing fold 4 ...\n",
      "Preparing fold 5 ...\n"
     ]
    }
   ],
   "source": [
    "prepare_folds(train, ORIGINAL_FEATURES, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71aebcb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:45.776193Z",
     "iopub.status.busy": "2024-01-01T19:29:45.775356Z",
     "iopub.status.idle": "2024-01-01T19:29:45.991449Z",
     "shell.execute_reply": "2024-01-01T19:29:45.990230Z"
    },
    "papermill": {
     "duration": 0.228705,
     "end_time": "2024-01-01T19:29:45.994501",
     "exception": false,
     "start_time": "2024-01-01T19:29:45.765796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49576712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:46.012575Z",
     "iopub.status.busy": "2024-01-01T19:29:46.011865Z",
     "iopub.status.idle": "2024-01-01T19:29:46.021457Z",
     "shell.execute_reply": "2024-01-01T19:29:46.020754Z"
    },
    "papermill": {
     "duration": 0.020943,
     "end_time": "2024-01-01T19:29:46.023529",
     "exception": false,
     "start_time": "2024-01-01T19:29:46.002586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features, dtype=torch.float)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.features[index]\n",
    "        y = self.targets[index]\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "\n",
    "def get_dataloader(features, targets, \n",
    "                       feature_names, \n",
    "                       target_name,\n",
    "                       batch_size,\n",
    "                       mode):\n",
    "    if mode == 'train':\n",
    "        shuffle = True\n",
    "        drop_last = True\n",
    "    else:\n",
    "        shuffle = False\n",
    "        drop_last = False\n",
    "    \n",
    "    torch.manual_seed(SEED)\n",
    "    train_dataset = SpamDataset(\n",
    "        features=features, \n",
    "        targets=targets\n",
    "    )\n",
    "    \n",
    "    data_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=N_CORES\n",
    "    )\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b204261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:46.041904Z",
     "iopub.status.busy": "2024-01-01T19:29:46.041063Z",
     "iopub.status.idle": "2024-01-01T19:29:46.066403Z",
     "shell.execute_reply": "2024-01-01T19:29:46.065445Z"
    },
    "papermill": {
     "duration": 0.037087,
     "end_time": "2024-01-01T19:29:46.068710",
     "exception": false,
     "start_time": "2024-01-01T19:29:46.031623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GatedLinearUnit(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(GatedLinearUnit, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, input_size)\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x) * self.gate(x)\n",
    "    \n",
    "    \n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.grn = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Dropout(dropout),\n",
    "            GatedLinearUnit(hidden_size),\n",
    "        )\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.feature_projection  = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.grn(inputs)\n",
    "        if inputs.shape[-1] != self.hidden_size:\n",
    "            inputs = self.feature_projection(inputs)\n",
    "        x = self.layer_norm(x + inputs)\n",
    "        return x\n",
    "    \n",
    "class VariableSelectionNetwork(nn.Module):\n",
    "    def __init__(self, num_features, dense_units, hidden_size, dropout):\n",
    "        super(VariableSelectionNetwork, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.grns = nn.ModuleList()\n",
    "        for _ in range(num_features):\n",
    "            self.grns.append(GatedResidualNetwork(dense_units, hidden_size, dropout))\n",
    "        \n",
    "        \n",
    "        self.grn_concat = GatedResidualNetwork(num_features*dense_units,  hidden_size, dropout)\n",
    "        self.softmax = nn.Sequential(\n",
    "            nn.Linear(hidden_size, num_features),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        v = torch.cat(inputs, dim=1)\n",
    "        v = self.grn_concat(v)\n",
    "        v = self.softmax(v)\n",
    "        v = torch.unsqueeze(v, dim=-1)\n",
    "        \n",
    "        x = []\n",
    "        for idx, input_ in enumerate(inputs):\n",
    "            x.append(self.grns[idx](input_))\n",
    "        x = torch.stack(x, dim=1)\n",
    "        \n",
    "        out = (v.transpose(2, 1) @ x).squeeze(dim=1)\n",
    "        return out\n",
    "    \n",
    "class VariableSelectionFlow(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, dense_units, dropout):\n",
    "        super(VariableSelectionFlow, self).__init__()\n",
    "        self.variable_selection = VariableSelectionNetwork(num_features, dense_units, hidden_size, dropout)\n",
    "        self.split = lambda x: torch.split(x, 1, dim=-1)\n",
    "        self.dense_list = nn.ModuleList(\n",
    "            [\n",
    "            nn.Linear(1, dense_units) \n",
    "            for _ in range(num_features)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        split_inputs = self.split(inputs)\n",
    "        x = []\n",
    "        for split_input, linear in zip(split_inputs, self.dense_list):\n",
    "            x.append(linear(split_input))\n",
    "            \n",
    "        return self.variable_selection(x)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, dense_units, hidden_sizes, dropouts):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.dense_units = dense_units\n",
    "        self.hidden_size_1 = hidden_sizes[0]\n",
    "        self.hidden_size_2 = hidden_sizes[1]\n",
    "        self.hidden_size_3 = hidden_sizes[2]\n",
    "\n",
    "        self.dropout_1 = dropouts[0]\n",
    "        self.dropout_2 = dropouts[1]\n",
    "        self.dropout_3 = dropouts[2]\n",
    "        \n",
    "        self.variable_slection_flows = nn.Sequential(\n",
    "            VariableSelectionFlow(num_features, self.hidden_size_1, dense_units, self.dropout_1),\n",
    "            VariableSelectionFlow(self.hidden_size_1, self.hidden_size_2, dense_units, self.dropout_2),\n",
    "            VariableSelectionFlow(self.hidden_size_2, self.hidden_size_3, dense_units, self.dropout_3),\n",
    "            nn.Linear(self.hidden_size_3, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.variable_slection_flows(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6058d4e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:46.087005Z",
     "iopub.status.busy": "2024-01-01T19:29:46.086630Z",
     "iopub.status.idle": "2024-01-01T19:29:46.100234Z",
     "shell.execute_reply": "2024-01-01T19:29:46.099168Z"
    },
    "papermill": {
     "duration": 0.025228,
     "end_time": "2024-01-01T19:29:46.102328",
     "exception": false,
     "start_time": "2024-01-01T19:29:46.077100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(model, optimizer, scheduler, epochs, train_dataloader, val_dataloader):\n",
    "\n",
    "    start_time = time.time()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, (features, targets) in enumerate(train_dataloader):\n",
    "            features = features.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            with autocast():\n",
    "                logits = model(features)\n",
    "                probs = F.softmax(logits, dim=-1)[:, 1]\n",
    "                loss = score(targets, probs)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "            if not batch_idx % 10:\n",
    "                print(\n",
    "                    f'Epoch: {epoch + 1}/{epochs}'\n",
    "                    f' | Batch: {batch_idx}/{len(train_dataloader)}'\n",
    "                    f' | Loss: {loss.detach().cpu().item():.4f}')\n",
    "\n",
    "        if val_dataloader is not None:\n",
    "            y_scores = torch.tensor([])\n",
    "            y_true = torch.tensor([])\n",
    "\n",
    "            with torch.inference_mode():\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "                for batch_idx, (features, targets) in enumerate(val_dataloader):\n",
    "                    features = features.to(DEVICE)\n",
    "                    with autocast():\n",
    "                        logits = model(features).detach().cpu().type(torch.float)\n",
    "                        probs = F.softmax(logits, dim=-1)[:, 1]\n",
    "                        y_scores = torch.cat([y_scores, probs])\n",
    "                        y_true = torch.cat([y_true, targets])\n",
    "\n",
    "                val_score = balanced_log_loss(y_true, y_scores)\n",
    "                print('Validation score (AUC):', val_score)\n",
    "\n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    print(f'Total training time: {elapsed:.3f} min')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    if val_dataloader is not None:\n",
    "        return model, val_score\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7117426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:46.121104Z",
     "iopub.status.busy": "2024-01-01T19:29:46.120221Z",
     "iopub.status.idle": "2024-01-01T19:29:46.124942Z",
     "shell.execute_reply": "2024-01-01T19:29:46.124215Z"
    },
    "papermill": {
     "duration": 0.016167,
     "end_time": "2024-01-01T19:29:46.126843",
     "exception": false,
     "start_time": "2024-01-01T19:29:46.110676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 15\n",
    "N_WARMUPS = 100\n",
    "WEIGHT_DECAY = 0.005\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf1b342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:46.145332Z",
     "iopub.status.busy": "2024-01-01T19:29:46.144673Z",
     "iopub.status.idle": "2024-01-01T19:29:46.151028Z",
     "shell.execute_reply": "2024-01-01T19:29:46.150011Z"
    },
    "papermill": {
     "duration": 0.018249,
     "end_time": "2024-01-01T19:29:46.153417",
     "exception": false,
     "start_time": "2024-01-01T19:29:46.135168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_scores = []\n",
    "# for fold in range(1, 6):\n",
    "#     df_train = pd.read_csv(OUTPUT_PATH  / f'df_train_fold_{fold}.csv')\n",
    "#     df_val = pd.read_csv(OUTPUT_PATH  / f'df_val_fold_{fold}.csv')\n",
    "#     imp = SimpleImputer(strategy='median')\n",
    "#     X_train = df_train[ORIGINAL_FEATURES]\n",
    "#     y_train = df_train[TARGET]\n",
    "#     X_val = df_val[ORIGINAL_FEATURES]\n",
    "#     y_val = df_val[TARGET]\n",
    "    \n",
    "#     X_train, X_val = imp.fit_transform(X_train), imp.transform(X_val)\n",
    "    \n",
    "#     train_dataloader = get_dataloader(\n",
    "#         X_train, y_train,\n",
    "#         feature_names=ORIGINAL_FEATURES, \n",
    "#         target_name=TARGET,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         mode='train'\n",
    "#     )\n",
    "    \n",
    "#     val_dataloader = get_dataloader(\n",
    "#         X_val, y_val, \n",
    "#         feature_names=ORIGINAL_FEATURES, \n",
    "#         target_name=TARGET,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         mode='val'\n",
    "#     )\n",
    "    \n",
    "#     torch.manual_seed(SEED)\n",
    "#     model = Net(\n",
    "#         num_features=NUM_FEATURES, \n",
    "#         dense_units=8,\n",
    "#         hidden_sizes=[32, 32, 32],\n",
    "#         dropouts=[0.75, 0.5, 0.1]\n",
    "#     )\n",
    "    \n",
    "#     model.to(DEVICE)\n",
    "#     model.train()\n",
    "    \n",
    "#     optimizer = optim.AdamW(\n",
    "#         model.parameters(), \n",
    "#         lr=LEARNING_RATE,\n",
    "#         weight_decay=WEIGHT_DECAY\n",
    "#     )\n",
    "    \n",
    "#     scheduler = get_cosine_schedule_with_warmup(\n",
    "#         optimizer=optimizer, \n",
    "#         num_warmup_steps=N_WARMUPS,\n",
    "#         num_training_steps=len(train_dataloader)*N_EPOCHS\n",
    "#     )\n",
    "    \n",
    "#     model, val_score = fit(model=model,\n",
    "#                            optimizer=optimizer,\n",
    "#                            scheduler=scheduler,\n",
    "#                            epochs=N_EPOCHS,\n",
    "#                            train_dataloader=train_dataloader,\n",
    "#                            val_dataloader=val_dataloader)\n",
    "    \n",
    "#     val_scores.append(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92dc4434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:46.171440Z",
     "iopub.status.busy": "2024-01-01T19:29:46.171085Z",
     "iopub.status.idle": "2024-01-01T19:29:46.176610Z",
     "shell.execute_reply": "2024-01-01T19:29:46.175869Z"
    },
    "papermill": {
     "duration": 0.016751,
     "end_time": "2024-01-01T19:29:46.178598",
     "exception": false,
     "start_time": "2024-01-01T19:29:46.161847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['Class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f67d8cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:29:46.197203Z",
     "iopub.status.busy": "2024-01-01T19:29:46.196547Z",
     "iopub.status.idle": "2024-01-01T19:30:59.588191Z",
     "shell.execute_reply": "2024-01-01T19:30:59.586463Z"
    },
    "papermill": {
     "duration": 73.403646,
     "end_time": "2024-01-01T19:30:59.590753",
     "exception": false,
     "start_time": "2024-01-01T19:29:46.187107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15 | Batch: 0/19 | Loss: 0.7048\n",
      "Epoch: 1/15 | Batch: 10/19 | Loss: 0.6967\n",
      "Epoch: 2/15 | Batch: 0/19 | Loss: 0.6925\n",
      "Epoch: 2/15 | Batch: 10/19 | Loss: 0.7254\n",
      "Epoch: 3/15 | Batch: 0/19 | Loss: 0.5173\n",
      "Epoch: 3/15 | Batch: 10/19 | Loss: 0.7123\n",
      "Epoch: 4/15 | Batch: 0/19 | Loss: 0.4894\n",
      "Epoch: 4/15 | Batch: 10/19 | Loss: 0.2931\n",
      "Epoch: 5/15 | Batch: 0/19 | Loss: 0.4056\n",
      "Epoch: 5/15 | Batch: 10/19 | Loss: 0.4076\n",
      "Epoch: 6/15 | Batch: 0/19 | Loss: 0.4935\n",
      "Epoch: 6/15 | Batch: 10/19 | Loss: 0.3445\n",
      "Epoch: 7/15 | Batch: 0/19 | Loss: 0.5423\n",
      "Epoch: 7/15 | Batch: 10/19 | Loss: 0.5617\n",
      "Epoch: 8/15 | Batch: 0/19 | Loss: 0.3421\n",
      "Epoch: 8/15 | Batch: 10/19 | Loss: 0.7682\n",
      "Epoch: 9/15 | Batch: 0/19 | Loss: 0.5203\n",
      "Epoch: 9/15 | Batch: 10/19 | Loss: 0.3110\n",
      "Epoch: 10/15 | Batch: 0/19 | Loss: 0.4536\n",
      "Epoch: 10/15 | Batch: 10/19 | Loss: 0.5030\n",
      "Epoch: 11/15 | Batch: 0/19 | Loss: 0.5255\n",
      "Epoch: 11/15 | Batch: 10/19 | Loss: 0.2635\n",
      "Epoch: 12/15 | Batch: 0/19 | Loss: 0.3376\n",
      "Epoch: 12/15 | Batch: 10/19 | Loss: 0.4615\n",
      "Epoch: 13/15 | Batch: 0/19 | Loss: 0.5024\n",
      "Epoch: 13/15 | Batch: 10/19 | Loss: 0.2413\n",
      "Epoch: 14/15 | Batch: 0/19 | Loss: 0.4117\n",
      "Epoch: 14/15 | Batch: 10/19 | Loss: 0.2432\n",
      "Epoch: 15/15 | Batch: 0/19 | Loss: 0.3910\n",
      "Epoch: 15/15 | Batch: 10/19 | Loss: 0.3647\n",
      "Total training time: 1.213 min\n"
     ]
    }
   ],
   "source": [
    "X_train = train[ORIGINAL_FEATURES]\n",
    "y_train = train[TARGET]\n",
    "X_test = test[ORIGINAL_FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "X_train, X_test = imp.fit_transform(X_train), imp.transform(X_test)\n",
    "\n",
    "train_dataloader = get_dataloader(\n",
    "    X_train, y_train,\n",
    "    feature_names=ORIGINAL_FEATURES, \n",
    "    target_name=TARGET,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode='train'\n",
    ")\n",
    "\n",
    "test_dataloader = get_dataloader(\n",
    "    X_test, y_test, \n",
    "    feature_names=ORIGINAL_FEATURES, \n",
    "    target_name=TARGET,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode='val'\n",
    ")\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model = Net(\n",
    "    num_features=NUM_FEATURES, \n",
    "    dense_units=8,\n",
    "    hidden_sizes=[32, 32, 32],\n",
    "    dropouts=[0.75, 0.5, 0.25]\n",
    ")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=N_WARMUPS,\n",
    "    num_training_steps=len(train_dataloader)*N_EPOCHS\n",
    ")\n",
    "\n",
    "model = fit(model=model,\n",
    "           optimizer=optimizer,\n",
    "           scheduler=scheduler,\n",
    "           epochs=N_EPOCHS,\n",
    "           train_dataloader=train_dataloader,\n",
    "           val_dataloader=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e157b23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:30:59.616895Z",
     "iopub.status.busy": "2024-01-01T19:30:59.616447Z",
     "iopub.status.idle": "2024-01-01T19:30:59.838258Z",
     "shell.execute_reply": "2024-01-01T19:30:59.837044Z"
    },
    "papermill": {
     "duration": 0.238962,
     "end_time": "2024-01-01T19:30:59.840939",
     "exception": false,
     "start_time": "2024-01-01T19:30:59.601977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_scores = torch.tensor([])\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for batch_idx, (features, targets) in enumerate(test_dataloader):\n",
    "        features = features.to(DEVICE)\n",
    "        with autocast():\n",
    "            logits = model(features).detach().cpu().type(torch.float)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            y_scores = torch.cat([y_scores, probs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013174b",
   "metadata": {
    "papermill": {
     "duration": 0.011217,
     "end_time": "2024-01-01T19:30:59.864280",
     "exception": false,
     "start_time": "2024-01-01T19:30:59.853063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ad834b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-01T19:30:59.889223Z",
     "iopub.status.busy": "2024-01-01T19:30:59.888758Z",
     "iopub.status.idle": "2024-01-01T19:30:59.932660Z",
     "shell.execute_reply": "2024-01-01T19:30:59.931613Z"
    },
    "papermill": {
     "duration": 0.059337,
     "end_time": "2024-01-01T19:30:59.935071",
     "exception": false,
     "start_time": "2024-01-01T19:30:59.875734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.923802</td>\n",
       "      <td>0.076198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.923802</td>\n",
       "      <td>0.076198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.923802</td>\n",
       "      <td>0.076198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.923802</td>\n",
       "      <td>0.076198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.923802</td>\n",
       "      <td>0.076198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.923802  0.076198\n",
       "1  010ebe33f668  0.923802  0.076198\n",
       "2  02fa521e1838  0.923802  0.076198\n",
       "3  040e15f562a2  0.923802  0.076198\n",
       "4  046e85c7cc7f  0.923802  0.076198"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\n",
    "sub[['class_0', 'class_1']] = y_scores\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "print('Submission file saved!')\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b514427",
   "metadata": {
    "papermill": {
     "duration": 0.011463,
     "end_time": "2024-01-01T19:30:59.958503",
     "exception": false,
     "start_time": "2024-01-01T19:30:59.947040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 5687476,
     "sourceId": 52784,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 5768690,
     "datasetId": 3273406,
     "sourceId": 5693071,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7382017,
     "datasetId": 930977,
     "sourceId": 7292109,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30474,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 104.093568,
   "end_time": "2024-01-01T19:31:02.855589",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-01T19:29:18.762021",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
